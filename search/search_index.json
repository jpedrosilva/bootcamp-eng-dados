{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"config/","title":"Config","text":"<p>load_db_settings </p> <p>Load database settings from environment variables.</p> <p>Reads the following environment variables from a <code>.env</code> file in the current working directory:</p> <ul> <li><code>POSTGRES_HOST</code> (str): The host of the PostgreSQL database.</li> <li><code>POSTGRES_USER</code> (str): The username for accessing the PostgreSQL database.</li> <li><code>POSTGRES_PASSWORD</code> (str): The password for accessing the PostgreSQL database.</li> <li><code>POSTGRES_DB</code> (str): The name of the PostgreSQL database.</li> <li><code>POSTGRES_PORT</code> (str): The port on which the PostgreSQL database is running.</li> </ul> <p>Returns:</p> Name Type Description <code>settings</code> <code>dict</code> <p>A dictionary containing the database settings.</p> Source code in <code>app\\modules\\config.py</code> <pre><code>@log_decorator\ndef load_db_settings() -&gt; dict:\n    \"\"\"\n    Load database settings from environment variables.\n\n    Reads the following environment variables from a `.env` file in the current working directory:\n\n    - `POSTGRES_HOST` (str): The host of the PostgreSQL database.\n    - `POSTGRES_USER` (str): The username for accessing the PostgreSQL database.\n    - `POSTGRES_PASSWORD` (str): The password for accessing the PostgreSQL database.\n    - `POSTGRES_DB` (str): The name of the PostgreSQL database.\n    - `POSTGRES_PORT` (str): The port on which the PostgreSQL database is running.\n\n    Returns:\n        settings: A dictionary containing the database settings.\n    \"\"\"\n    dotenv_path = Path.cwd() / \".env\"\n    load_dotenv(dotenv_path=dotenv_path)\n\n    settings = {\n        \"db_host\": getenv(\"POSTGRES_HOST\"),\n        \"db_user\": getenv(\"POSTGRES_USER\"),\n        \"db_pass\": getenv(\"POSTGRES_PASSWORD\"),\n        \"db_name\": getenv(\"POSTGRES_DB\"),\n        \"db_port\": getenv(\"POSTGRES_PORT\"),\n    }\n    return settings\n</code></pre> <p>create_connection_string_postgre </p> <p>Create a connection string for PostgreSQL.</p> <p>This function uses the settings loaded from environment variables to create a connection string for connecting to a PostgreSQL database.</p> <p>Returns:</p> Name Type Description <code>connection_string</code> <code>str</code> <p>The connection string formatted as \"postgresql://username:password@host:port/database\".</p> Source code in <code>app\\modules\\config.py</code> <pre><code>@log_decorator\ndef create_connection_string_postgre() -&gt; str:\n    \"\"\"\n    Create a connection string for PostgreSQL.\n\n    This function uses the settings loaded from environment variables to create a connection string\n    for connecting to a PostgreSQL database.\n\n    Returns:\n        connection_string: The connection string formatted as \"postgresql://username:password@host:port/database\".\n    \"\"\"\n    settings = load_db_settings()\n    connection_string = f\"postgresql://{settings['db_user']}:{settings['db_pass']}@{settings['db_host']}:{settings['db_port']}/{settings['db_name']}\"\n    return connection_string\n</code></pre> <p>test_connection_postgre </p> <p>Tests the connection to a PostgreSQL database.</p> <p>This function creates an engine using the connection string generated by create_connection_string_postgre(), connects to the database, and prints a success message if the connection is successful.</p> <p>Raises:</p> Type Description <code>SQLAlchemyError</code> <p>If there is an error connecting to the database.</p> Source code in <code>app\\modules\\config.py</code> <pre><code>@log_decorator\ndef test_connection_postgre() -&gt; None:\n    \"\"\"\n    Tests the connection to a PostgreSQL database.\n\n    This function creates an engine using the connection string generated by\n    create_connection_string_postgre(), connects to the database, and prints\n    a success message if the connection is successful.\n\n    Raises:\n        sqlalchemy.exc.SQLAlchemyError: If there is an error connecting to the database.\n    \"\"\"\n    engine = create_engine(create_connection_string_postgre())\n    with engine.connect() as conn, conn.begin():\n        print(\"A conex\u00e3o com o banco de dados foi bem-sucedida.\")\n</code></pre>"},{"location":"extract/","title":"Extract","text":"<p>extract_data_pd </p> <p>Extracts data from a database using a provided SQL query and returns it as a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>connection_string</code> <code>str</code> <p>The connection string to connect to the database.</p> required <code>query</code> <code>str</code> <p>The SQL query to execute.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A pandas DataFrame containing the results of the query.</p> Source code in <code>app\\modules\\extract_data.py</code> <pre><code>@log_decorator\n@time_measure_decorator\n@validate_call\ndef extract_data_pd(connection_string: str, query: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Extracts data from a database using a provided SQL query and returns it as a pandas DataFrame.\n\n    Args:\n        connection_string (str): The connection string to connect to the database.\n        query (str): The SQL query to execute.\n\n    Returns:\n        pd.DataFrame: A pandas DataFrame containing the results of the query.\n    \"\"\"\n    engine = create_engine(connection_string)\n\n    with engine.connect() as conn, conn.begin():\n        df = pd.read_sql_query(query, conn)\n    return df\n</code></pre>"},{"location":"input-schemas/","title":"Input Schemas","text":"<p>ImportWeatherStationSchema </p> <p>             Bases: <code>SchemaModel</code></p> <p>Defines the schema for importing weather station data.</p> <p>Attributes:</p> Name Type Description <code>city</code> <code>Series[str]</code> <p>The city where the weather station is located.</p> <code>value</code> <code>Series[float]</code> <p>The value measured by the weather station, constrained to be greater than or equal to -1000 and less than or equal to 1000.</p> Config <p>coerce (bool): Whether to coerce values to the specified types.</p> Source code in <code>app\\modules\\schemas.py</code> <pre><code>class ImportWeatherStationSchema(pa.SchemaModel):\n    \"\"\"\n    Defines the schema for importing weather station data.\n\n    Attributes:\n        city (pandas.Series[str]): The city where the weather station is located.\n        value (pandas.Series[float], optional): The value measured by the weather station,\n            constrained to be greater than or equal to -1000 and less than or equal to 1000.\n\n    Config:\n        coerce (bool): Whether to coerce values to the specified types.\n    \"\"\"\n\n    city: Series[str]\n    value: Series[float] = pa.Field(ge=-1000, le=1000)\n\n    class Config:\n        coerce = True\n</code></pre>"},{"location":"load/","title":"Load","text":"<p>read_csv_file </p> <p>Read a CSV file into a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to the CSV file.</p> required <code>delimiter</code> <code>str</code> <p>The delimiter used in the CSV file.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A pandas DataFrame containing the data from the CSV file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified file does not exist.</p> <code>Exception</code> <p>If any other error occurs while reading the file.</p> Source code in <code>app\\modules\\load_data.py</code> <pre><code>@log_decorator\n@validate_call\ndef read_csv_file(path: Path, delimiter: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Read a CSV file into a pandas DataFrame.\n\n    Args:\n        path (Path): The path to the CSV file.\n        delimiter (str): The delimiter used in the CSV file.\n\n    Returns:\n        pd.DataFrame: A pandas DataFrame containing the data from the CSV file.\n\n    Raises:\n        FileNotFoundError: If the specified file does not exist.\n        Exception: If any other error occurs while reading the file.\n    \"\"\"\n    try:\n        if Path(path).is_file() == False:\n            raise FileNotFoundError\n        else:\n            df = pd.read_csv(\n                path, delimiter=delimiter, encoding=\"utf-8\", header=0, index_col=False\n            )\n            return df\n    except FileNotFoundError as e:\n        raise FileNotFoundError(\n            f\"O arquivo para carregamento n\u00e3o foi encontrado. ERROR: {e}\"\n        )\n    except Exception:\n        raise Exception\n</code></pre> <p>load_table_postgre </p> <p>Load a pandas DataFrame into a PostgreSQL table.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to be loaded into the table.</p> required <code>table</code> <code>str</code> <p>The name of the table in the PostgreSQL database.</p> required <code>schema</code> <code>str</code> <p>The name of the schema in the PostgreSQL database.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>app\\modules\\load_data.py</code> <pre><code>@log_decorator\n@validate_call\ndef load_table_postgre(df, table: str, schema: str) -&gt; None:\n    \"\"\"\n    Load a pandas DataFrame into a PostgreSQL table.\n\n    Args:\n        df (DataFrame): The DataFrame to be loaded into the table.\n        table (str): The name of the table in the PostgreSQL database.\n        schema (str): The name of the schema in the PostgreSQL database.\n\n    Returns:\n        None\n    \"\"\"\n    # Cria\u00e7\u00e3o da engine\n    engine = create_engine(create_connection_string_postgre())\n\n    # Barra de progresso\n    print(f\"Carga da tabela {table} iniciada.\")\n    chunksize = int(len(df) / 10)\n    with tqdm(total=len(df)) as pbar:\n        for i, cdf in enumerate(chuncker(df, chunksize)):\n            replace = \"replace\" if i == 0 else \"append\"\n            cdf.to_sql(\n                name=table,\n                schema=schema,\n                con=engine,\n                if_exists=replace,\n                index=False,\n                method=\"multi\",\n            )\n            pbar.update(chunksize)\n    print(f\"Carga da tabela {table} finalizada com sucesso.\")\n</code></pre>"},{"location":"output-schemas/","title":"Input Schemas","text":"<p>TransformWeatherStationSchema </p> <p>             Bases: <code>SchemaModel</code></p> <p>Schema for transforming weather station data.</p> <p>Attributes:</p> Name Type Description <code>city</code> <code>Series[str]</code> <p>The city name.</p> <code>max_value</code> <code>Series[float]</code> <p>The maximum temperature value.</p> <code>min_value</code> <code>Series[float]</code> <p>The minimum temperature value.</p> <code>avg_value</code> <code>Series[float]</code> <p>The average temperature value.</p> Config <p>coerce (bool): Whether to coerce values to the specified types.</p> Source code in <code>app\\modules\\schemas.py</code> <pre><code>class TransformWeatherStationSchema(pa.SchemaModel):\n    \"\"\"\n    Schema for transforming weather station data.\n\n    Attributes:\n        city (Series[str]): The city name.\n        max_value (Series[float]): The maximum temperature value.\n        min_value (Series[float]): The minimum temperature value.\n        avg_value (Series[float]): The average temperature value.\n\n    Config:\n        coerce (bool): Whether to coerce values to the specified types.\n    \"\"\"\n\n    city: Series[str]\n    max_value: Series[float]\n    min_value: Series[float]\n    avg_value: Series[float]\n\n    class Config:\n        coerce = True\n</code></pre>"},{"location":"transform/","title":"Transform","text":"<p>aggregate_df_using_polars </p> <p>Aggregate a DataFrame using Polars.</p> <p>If the input DataFrame is a pandas DataFrame, it will be converted to a Polars DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>groupby_col</code> <code>str</code> <p>The column to group by.</p> required <code>measure_col</code> <code>str</code> <p>The column to aggregate.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: The aggregated DataFrame, containing maximum, minimum, and mean values of the measure_col for each group in groupby_col, sorted by groupby_col.</p> Source code in <code>app\\modules\\transform_data.py</code> <pre><code>@log_decorator\n@time_measure_decorator\n@validate_call\n@pa.check_input(ImportWeatherStationSchema, lazy=True)\ndef aggregate_df_using_polars(df, groupby_col: str, measure_col: str) -&gt; pl.DataFrame:\n    \"\"\"\n    Aggregate a DataFrame using Polars.\n\n    If the input DataFrame is a pandas DataFrame, it will be converted to a Polars DataFrame.\n\n    Args:\n        df (DataFrame): The input DataFrame.\n        groupby_col (str): The column to group by.\n        measure_col (str): The column to aggregate.\n\n    Returns:\n        pl.DataFrame: The aggregated DataFrame, containing maximum, minimum, and mean values of the measure_col for each group in groupby_col, sorted by groupby_col.\n    \"\"\"\n    if isinstance(df, pd.DataFrame):\n        df = pl.from_pandas(df)\n\n    df_grouped = (\n        df.groupby(by=groupby_col)\n        .agg(\n            max=pl.col(measure_col).max().alias(f\"max_{measure_col}\"),\n            min=pl.col(measure_col).min().alias(f\"min_{measure_col}\"),\n            mean=pl.col(measure_col).mean().alias(f\"mean_{measure_col}\"),\n        )\n        .sort(groupby_col)\n    )\n    return df_grouped\n</code></pre> <p>aggregate_df_using_duckdb </p> <p>Aggregate a DataFrame using DuckDB.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>groupby_col</code> <code>str</code> <p>The column to group by.</p> required <code>measure_col</code> <code>str</code> <p>The column to aggregate.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The aggregated DataFrame, containing maximum, minimum, and mean values of the measure_col for each group in groupby_col, sorted by groupby_col.</p> Source code in <code>app\\modules\\transform_data.py</code> <pre><code>@log_decorator\n@time_measure_decorator\n@validate_call\n@pa.check_input(ImportWeatherStationSchema, lazy=True)\n@pa.check_output(TransformWeatherStationSchema, lazy=True)\ndef aggregate_df_using_duckdb(df, groupby_col: str, measure_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Aggregate a DataFrame using DuckDB.\n\n    Args:\n        df (DataFrame): The input DataFrame.\n        groupby_col (str): The column to group by.\n        measure_col (str): The column to aggregate.\n\n    Returns:\n        pd.DataFrame: The aggregated DataFrame, containing maximum, minimum, and mean values of the measure_col for each group in groupby_col, sorted by groupby_col.\n    \"\"\"\n    if isinstance(df, pl.DataFrame):\n        df = pl.to_pandas(df)\n    df_grouped = duckdb.query(\n        f\"\"\"SELECT {groupby_col} as {groupby_col},\n                        MAX({measure_col}) as max_{measure_col},\n                        MIN({measure_col}) as min_{measure_col},\n                        AVG({measure_col}) as avg_{measure_col}\n                FROM df\n                GROUP BY {groupby_col}\n                ORDER BY {groupby_col}\n             \"\"\"\n    ).to_df()\n    return df_grouped\n</code></pre>"}]}